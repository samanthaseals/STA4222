---
title: "Sampling with Unequal Probabilities without Replacement"
subtitle: "Chapter 6 - Part 2"
author: "Dr. Seals"
execute:
  echo: true
  warning: false
  message: false
format: 
  revealjs:
    theme: uwf
    self-contained: true
    slide-number: false
    footer: "[STA4222 - Sampling Theory](https://samanthaseals.github.io/STA4222)"
    width: 1600
    height: 900
    df-print: paged
    html-math-method: katex
editor: source
---

## Introduction

- Last week we discussed sampling with unequal probabilities with replacement.

    - If we can sample with replacement, the estimation processes are much easier.
    
- We found that under unequal probability selection, the variance of the estimator can decrease.

- However, with the wrong specification of $\psi_i$, we can also increae the variance of the estimator. 

- Today, we will expand what we know and learn about unequal probability sampling without replacement.

## 6.4: Unequal Probability Sampling without Replacement

- Generally, sampling with replacement is less efficient than sampling without replacement.

    - This means that the variance is higher when we sample with replacement.
    
- To demonstrate concepts, let's return to the supermarket example from 6.1,

| Store | Size (m^2^) | $\psi_i$ | $t_i$ (in thousands) | 
|:-:|:-:|:-:|:-:|
| A | 100 | 1/16 | 11 |
| B | 200 | 2/16 | 20 |
| C | 300 | 3/16 | 24 |
| D | 1000 | 10/16 | 245 |
| Total | 1600 | 1 | 300 |

## 6.4: Unequal Probability Sampling without Replacement

- Now, let's define probabilities, $$\begin{align*}\text{P}[\text{unit $k$ chosen first, unit $i$ chosen second}] &= \text{P}[\text{unit $i$ chosen second | unit $k$ chosen first}] \\ &= \psi_k \frac{\psi_i}{1-\psi_k}\end{align*}$$

- Applying this to our supermarket example, $$\begin{align*}\text{P}[\text{A chosen first, B chosen second}] &= \text{P}[\text{B chosen second | A chosen first}] \\ &= \psi_{\text{A}} \frac{\psi_{\text{B}}}{1-\psi_{\text{A}}} \\ &= \frac{\frac{2}{16}}{1-\frac{1}{16}}\end{align*}$$

## 6.4: Unequal Probability Sampling without Replacement

- We now can compute the probability that cluster $i$ is included in the sample, $$\pi_i = \sum_{i \in \mathscr{S}} \text{P}[\mathscr{S}]$$

- For the supermarket data, <center><img src = "images/L09a.png"></center>

    - Inside the table is $\pi_{ik}$, the joint inclusion probability of the specific sample of $n=2$.
    
    - The margins have $\pi_i$, the inclusion probabilities for each store.

        - Note that $\pi_i = \pi_k$ when $i = k$.

## 6.4: Unequal Probability Sampling without Replacement

- Assume that we have a without replacement sample of $n$ clusters and we know the inclusion probability, $\pi_i$, $$\pi_i = \text{P}[\text{unit $i$ in sample}]$$ and the joint inclusion probability, $\pi_{ik}$, $$\pi_i = \text{P}[\text{units $i$ and $k$ are both in the sample}]$$

- The inclusion probability, $\pi_i$, can be calculated as the sum of the probabilities of all samples containing the $i^{\text{th}}$ unit and $$\sum_{i=1}^N \pi_i = n$$

- Further, for the joint inclusion probabilities, $$\sum_{k=1 \text{ where } k \ne i}^N \pi_{ik} = (n-1) \pi_i$$

## 6.4: Unequal Probability Sampling without Replacement

- The Horvitz-Thompson (HT) estimator of $\tau$ is as follows, $$\hat{\tau}_{\text{HT}} = \sum_{i \in \mathscr{S}} \frac{\hat{\tau}_i}{\pi_i} = \sum_{i=1}^N Z_i \frac{\hat{\tau}_i}{\pi_i},$$ where $Z_i=1$ if cluster $i$ is included in the sample, 0 otherwise.

- The corresponding variance estimator, $$\hat{\text{var}}[\hat{\tau}_{\text{HT}}] = \frac{1}{2} \sum_{i \in \mathscr{S}} \sum_{k \in \mathscr{S}, \text{ where } k \ne i} \frac{\pi_i \pi_k - \pi_{ik}}{\pi_{ik}}\left(\frac{\hat{\tau}_i}{\pi_i} - \frac{\hat{\tau}_k}{\pi_k} \right)^2 $$

## 6.4: Unequal Probability Sampling without Replacement

- Suppose we take a sample of stores C and D,

| Store | Size (m^2^) | $\psi_i$ | $t_i$ (in thousands) | 
|:-:|:-:|:-:|:-:|
| C | 300 | 3/16 | 24 |
| D | 1000 | 10/16 | 245 |

<center><img src = "images/L09a.png"></center>

- Estimate $\tau$ and the variance of $\hat{\tau}_{\text{HT}}$.

## 6.4: Unequal Probability Sampling without Replacement

- Estimate $\tau$, $$\begin{align*}\hat{\tau}_{\text{HT}} &= \sum_{i \in \mathscr{S}} \frac{\hat{\tau}_i}{\pi_i} \\ &= \frac{245}{0.9002} + \frac{24}{0.5393} \\ &= 316.6639 \end{align*}$$

- and the variance, $$\begin{align*}\hat{\text{var}}[\hat{\tau}_{\text{HT}}] &= \frac{1}{2} \sum_{i \in \mathscr{S}} \sum_{k \in \mathscr{S}, \text{ where } k \ne i} \frac{\pi_i \pi_k - \pi_{ik}}{\pi_{ik}}\left(\frac{\hat{\tau}_i}{\pi_i} - \frac{\hat{\tau}_k}{\pi_k} \right)^2 \\ &= \frac{(0.9002)(0.5393)-0.4567}{0.4567} \left( \frac{245}{0.9002} - \frac{24}{0.5393} \right)^2 \\ &= 3259.8 \end{align*}$$

## 6.4: Unequal Probability Sampling without Replacement

- Recall the first stage sampling weight for cluster $i$, $$w_i = \frac{1}{\pi_i}$$

- We can rewrite the estimator for the population total, $$\hat{\tau}_{\text{HT}} = \sum_{i \in \mathscr{S}} w_i \hat{\tau}_i$$

- When we are taking a without replacement sample of individual units from clusters,  $$\pi_{j|i} = \text{P}[\text{$j^{\text{th}}$ unit in $i^{\text{th}}$ cluster chosen $|$  $i^{\text{th}}$ cluster in the sample}]$$

- Then, the overall probability that unit $j$ of cluster $i$ is in the sample, $$\pi_{j|i}\pi_i$$

## 6.4: Unequal Probability Sampling without Replacement

- Then, $$\hat{\tau}_i = \sum_{j \in \mathscr{S}_i} \frac{y_{ij}}{\pi_{j|i}}$$ and the Horvitz-Thompson estimator of the population total, $$\hat{\tau}_{\text{HT}} = \sum_{i \in \mathscr{S}} \sum_{j \in \mathscr{S}_i} w_{ij} y_{ij}$$

- We can estimate the variance, $$\hat{\text{var}}\left[ \hat{\tau}_{\text{HT}} \right] = \frac{1}{2} \sum_{i \in \mathscr{S}} \sum_{k \in \mathscr{S}, \text{ where } k \ne i} \frac{\pi_{ik} - \pi_i \pi_k}{\pi_{ik}} \frac{\hat{\tau}_i}{\pi_i} \frac{\hat{\tau}_k}{\pi_k} + \sum_{i \in \mathscr{S}} \frac{\hat{\text{var}}\left[ \hat{\tau}_i \right]}{\pi_i}$$ *however*, the textbook recommends using the with-replacement variance estimator, $$\hat{\text{var}}\left[ \hat{\tau}_{\text{HT}} \right] = \frac{n}{n-1} \sum_{i \in \mathscr{S}} \left( \frac{\hat{\tau}_i}{\pi_i} - \frac{\hat{\tau}_{\text{HT}}}{n} \right)^2$$

## 6.4: Unequal Probability Sampling without Replacement

- The estimator for the population mean, $$\bar{y}_{\text{HT}} = \frac{\sum_{i \in \mathscr{S}} \sum_{j \in \mathscr{S}_i} w_{ij} y_{ij}}{\sum_{i \in \mathscr{S}} \sum_{j \in \mathscr{S}_i} w_{ij}}$$

- We can estimate the variance, $$\hat{\text{var}}\left[ \bar{y}_{\text{HT}} \right] = \frac{n}{n-1} \sum_{i \in \mathscr{S}} \left( \frac{\sum_{j \in \mathscr{S}_i} w_{ij} (y_{ij}-\bar{y}_{\text{HT}})}{\sum_{k \in \mathscr{S}} \sum_{j \in \mathscr{S}_i} w_{kj}} \right)^2$$

## 6.4: Unequal Probability Sampling without Replacement

- Let's take a two-stage unequal-probability sample without replacement from the population of statistics classes in the previous example. 

- We want the cluster inclusion probabilities to be proportional to the class sizes, $M_i$, given previously. 

- The data are in the dataset **classpps** and in Table 6.8.

```{r}
library(tidyverse)
library(SDAResources)
data("classpps")
head(classpps, n=3)
```

## 6.4: Unequal Probability Sampling without Replacement

- Where did the weight (*finalweight*) come from?

```{r}
classpps %>% count(class)
```

- The same number of students ($m_i = 4$) were selected from each of the $n = 5$ classes.

- The cluster inclusion probabilities, $\pi_i$, are proportional to the class sizes, $M_i$. Thus, $$\frac{647}{20} = 32.35$$

## 6.4: Unequal Probability Sampling without Replacement

- Now to estimate the population total, $$\hat{\tau}_{\text{HT}} = \sum_{i \in \mathscr{S}} \sum_{j \in \mathscr{S}_i} w_{ij} y_{ij}$$

```{r}
classpps <- classpps %>% mutate(t = hours*finalweight)
(tau_hat_HT = sum(classpps$t))
```

- Thus, $\hat{\tau}_{\text{HT}} = 2232.15$.

## 6.4: Unequal Probability Sampling without Replacement

- Now to estimate the variance of the estimator,

$$\hat{\text{var}}\left[ \hat{\tau}_{\text{HT}} \right] = \frac{n}{n-1} \sum_{i \in \mathscr{S}} \left( \frac{\hat{\tau}_i}{\pi_i} - \frac{\hat{\tau}_{\text{HT}}}{n} \right)^2$$

- This means that we need to find $\hat{\tau}_i$ and $\hat{\tau}_i/\pi_i$,

```{r}
classpps <- classpps %>% 
  mutate(weight = class_size/4,
         tau = weight*hours)
summary <- classpps %>% 
  group_by(class) %>%
  summarize(tau_i = sum(tau),
            M_i = class_size,
            pi_i = (M_i/647)*5,
            frac = tau_i / pi_i,
            deviance = (frac - tau_hat_HT/5)^2) %>%
  unique()
```

## 6.4: Unequal Probability Sampling without Replacement

- That resulted in a summary dataset,
```{r}
head(summary, n = 2)
```

- Now, we are ready to find the variance, $$\hat{\text{var}}\left[ \hat{\tau}_{\text{HT}} \right] = \frac{n}{n-1} \sum_{i \in \mathscr{S}} \left( \frac{\hat{\tau}_i}{\pi_i} - \frac{\hat{\tau}_{\text{HT}}}{n} \right)^2,$$
```{r}
n = nrow(summary)
(var = (n/(n-1)) * sum(summary$deviance))
```

- Thus, $\hat{\text{var}}\left[ \hat{\tau}_{\text{HT}} \right] = 97195.78$.

## 6.4: Unequal Probability Sampling without Replacement

- To find the confidence interval, we need the margin of error,

```{r}
(MOE_tau = qt(0.975, n-1)*sqrt(var))
```

- Then we can find the bounds,

```{r}
(LB = tau_hat_HT - MOE_tau)
(UB = tau_hat_HT + MOE_tau)
```

- Thus, the 95% CI for $\tau$ is $(1366.559, 3097.741)$.

## Homework

ðŸ˜Ž